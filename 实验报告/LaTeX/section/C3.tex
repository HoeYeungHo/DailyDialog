\section{模型的构建与实现}\label{sec:3}

此次实验为了探究预训练编码模型BERT对于对情感识别领域中的对话情感识别的作用。本章首先介绍此次实验所用到的数据集，然后介绍主要模型的结构，最后给出实验结果和实验的各种细节。

\subsubsection{数据集与预处理过程}

本次实验的数据集来自DailyDialog\cite{dailydialog}，这是一个用于对话系统和情感识别的常用数据集。数据集中的对话是来自于日常生活中真实的对话，包括了多样的情感和语境。相比于来源于Twitter和微博的数据集，DailyDialog数据集中的数据来自于英语学习者相关的网站，并且使用了一个开源的英文自动纠错程序来消除了简单的英语单词拼写错误问题，使其主题相对集中，语法相对规范。一个数据实例如表\ref{table:DailyDialog}所示。

\input{table/DailyDialog}

对于对话中的每一个句子，都标注了对话的行动与情感。其中，行动标签分为4类，分别为：通知、提问、指令和承诺，情感标签分为7类，分别为：没有情绪、愤怒，厌恶、恐惧、快乐、悲伤和惊讶，其中没有情绪标签在预测时需要被剔除。情感标签的占比如图\ref{fig:EmotionPI}所示。

\input{fig/EmotionPI}

DailyDialog数据集一共有13118个对话，每轮对话大概有7.8轮且每个句子中大约有29.1个单词。每个对话的轮数以及每个句子中token的个数的箱线图与描述性统计分析如图\ref{fig:sentenceNum}和表\ref{table:sentenceNum}所示。

\input{fig/sentenceNum}

\input{table/sentenceNum}

\subsection{模型的构建}

如前所述，BERT模型对应于[CLS]的输出包含了整个输入句子的语义信息，可以使用这个语义语义信息经过一个分类器得到这句话对应的情感。在对话情感识别中，对话的上下文也包含了一定有助于情感识别的信息，所以在使用BERT编码每个句子之后没有直接利用分类器对句子进行分类，而是利用一个LSTM网络让其获取对话上下文的信息再进行分类。此外，对话的行动也有可能对对话的情感有一定的影响，所以在此次实验中构建了一个多任务的分类器，以促进两个任务的学习。模型的结构如图\ref{fig:MyModel}所示。

\input{fig/MyModel}

我进行了多次的消融实验，经过对比分析上述的假设是成立的，且经过预训练的模型BERT对情感识别任务具有强大的作用。

\subsection{实验细节与结果分析}

所有实现均在一台配备RTX 3090显卡（24GB）的Ubuntu计算机上使用PyTorch 2.0完成。由于显存的限制，批量大小均设置为4，学习率设置为$1\mathrm{e}-6$并使用了学习率预热和衰减的方法。

\subsubsection{预训练BERT模型对实验结果的影响}

首先，使用预训练的BERT模型与LSTM组成神经网络，并利用全量更新的方式对模型进行训练。从图\ref{fig:Base}可以看出，对于分类任务而言，由于预训练模型的使用，在第125个batch时就已经收敛到比较高的水平，在验证集中情感分类准确率达到65.03\%。最终在第700个batch达到最高水平，在验证集中情感分类准确率达到66.82\%，且在测试集中的情感分类准确率达到63.10\%。

\input{fig/Base}

在对BERT参数冻结之后，虽然效果相比于全参微调要差（在验证集中情感分类准确率达到64.80\%，且在测试集中的情感分类准确率达到60.59\%），但是由于其不用计算和存储BERT模型参数的梯度，所以计算速度和显存占用量都比全参微调要好，也是一种不错的选择。此外，在对BERT参数重置之后，由于没有使用预训练而直接微调，模型一直无法得到准确的预测。从另一个方面也说明，预训练模型中预训练与微调结合的方法是必不可少的。

\input{fig/PreTraingBert}

此外，还使用了更大规模的$\text{BERT}_\text{LARGE}$模型进行了比较。由于显存的限制，我冻结了BERT模型的参数，以便进行对比分析。尽管已经对后续神经网络进行了调整，但在投入更多计算资源的情况下，并未观察到性能的显著提升。这表明模型规模的增大并非总能带来更好的效果。对于小型任务，选择规模较小的模型可能会带来更高的效率和更优越的性能，这一点值得注意。

\input{fig/LargeBert}

\subsubsection{多任务损失对实验结果的影响}

该实验采用了多任务损失函数，要求BERT和LSTM结构同时学习情感分类和行动分类的信息。当将损失平衡因子$\alpha$设为0时，观察到情感分类准确率下降，表明这种多任务损失对情感分类准确性有所帮助。设置$\alpha$为0.5时，情感分类准确率达到最高值，在测试集中达到了63.33\%。

另外，值得注意的是行动分类的准确率较低。即便将损失平衡因子$\alpha$设为5，准确率仍有所提升但仍然偏低，在测试集上仅为46.73\%。因此，我将多任务损失函数改为仅针对行动进行预测，然而即便如此，行动分类的准确率仍然较低，这表明该模型结构可能不太适用于行动分类任务。

\input{fig/alpha}

值得说明的是，由于将损失平衡因子$\alpha$设置为0.5之后情感分类准确率最高，所以后续的实验均设置$\alpha=0.5$。

\subsubsection{改进模型的结构对实验结果的影响}

\paragraph{BiLSTM网络}

鉴于LSTM网络只能捕获下文信息，我尝试将其改为BiLSTM网络，以便获取上下文信息。然而，我发现准确率提升并不明显，如图\ref{fig:bidirectional2}中黄线所示。这可能是因为使用BiLSTM网络后，参数和输出维度都会翻倍。为了解决这一问题，我将BiLSTM网络中的双层结构改为单层，观察到情感识别准确率有所提升。在验证集上达到了69.91\%，在测试集上达到了65.91\%的准确率。

\input{fig/bidirectional2}

\paragraph{更大的模型结构}

在此次实验中，LSTM的输出维度为1024，BiLSTM的输出维度为$1024\times 2 = 2048$，而情绪和行动分类个数分别为6类和4类，维度的骤降可能不利于模型的泛化，所以我使用了两层的全连接层，其中添加的隐藏层有512个神经元。但是模型的整体表现不佳。

\input{fig/size}

为了进一步增加模型的表达能力，我采用了BiLSTM模型，并适当增加了全连接层的宽度，将隐藏层的输入维度设为4096，输出维度设为1024，并尝试了不同的Dropout参数进行对比。结果显示，采用更大规模的模型在验证集上的效果更佳，但仍然存在过拟合问题。

\input{fig/Dropout2}

\paragraph{RNN和GRU}

正如之前提到的，除了LSTM网络外，循环神经网络还包括RNN网络和GRU网络等变种。我对比了将LSTM网络替换为其他类型的循环神经网络。结果显示，采用RNN网络的准确率比使用LSTM网络和GRU网络更高。在验证集上，准确率达到了66.59\%，在测试集上也有64.54\%的准确率。

\input{fig/structure}

\subsubsection{不使用上下文信息对实验结果的影响}

由于预训练编码模型BERT经过大量数据进行无监督预训练，并在多种下游任务中进行微调，其编码能力很强大，所以我也尝试不使用循环神经网络融合上下文信息，直接将BERT的输出传递给前连接层，发现获得比较好的效果。在平衡因子$\alpha$设为0.5时，$\text{BERT}_\text{BASE}$模型在测试集中的情感分类准确率达到了70.99\%，不经过微调的$\text{BERT}_\text{LARGE}$模型的准确率也有70.16\%。此外，从图\ref{fig:context}中可以看出，$\text{BERT}_\text{BASE}$模型刚开始训练就已经达到很高的准确率。

\input{fig/context}

从\ref{fig:context}图中可以看出，使用LSTM提取上下文信息可能会削弱预训练编码模型BERT的表达能力，反而会让分类任务性能有所下降。另外，当平衡因子$\alpha$设为1时，我们获得了本次实验最佳且最平衡的成绩\footnote{为了获得最均衡的成绩，保存的模型是总分类准确率最好的模型而不是情感分类准确率最好的模型。}。在测试集中，情感分类准确率达到了70.99\%，行动分类准确率达到了71.80\%，总体分类准确率达到了71.40\%。

\input{fig/theBest}

\subsubsection{实验结果汇总与分析}

除了上述所描述的实验结果，本实验还针对其他参数做了许多消融实验，实验结果如表\ref{table:result}所示。其中，下划线为影响某个因素中的最好结果，加粗为整个实验中的最好结果。

\begin{landscape}
	\zihao{6}
	\input{table/result}
\end{landscape}


从上述实验可以看出，预训练编码模型BERT具有强大的表达能力，在经过较少的训练就能够达到很好的性能。在使用预训练编码模型时应该注意：

\begin{itemize}
	\item \textbf{分类器的复杂度平衡：}针对简单的分类任务时，选择的分类器应该匹配任务的复杂度。过于复杂的分类器可能会削弱预训练模型原有的表达能力。因此，在设计分类器时需要在精度和模型复杂度之间取得平衡。
	\item \textbf{任务大小与预训练模型的选择：}根据任务的规模和复杂程度选择适当大小的预训练编码模型是至关重要的。对于小型任务，选择相对较小的预训练模型既能提高模型的性能，又能提升模型运行的效率。这样做还有助于减少资源需求，加快训练和推理速度。
	\item \textbf{迁移学习策略：}在使用预训练编码模型时，需要考虑迁移学习的策略。有时候，仅冻结预训练模型的底层，只微调顶层，或者通过逐步解冻层来逐渐微调模型，都是有效的迁移学习策略。选择适当的策略有助于平衡模型的泛化能力和训练速度。
	\item \textbf{领域特定的微调：}某些情况下，预训练编码模型的泛化能力可能不足以完全适应特定领域的任务。在这种情况下，需要考虑在预训练模型上进行领域特定的微调，以提高模型在特定领域的性能。
	\item \textbf{超参数调整：}不同的任务和数据集可能需要不同的超参数设置。对于使用预训练编码模型的任务，经常需要对学习率、批量大小、优化器等超参数进行调整，以获得更好的性能。
\end{itemize}


















































































